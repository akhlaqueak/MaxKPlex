#!/bin/bash
# normal command for interactive session: srun --ntasks=2 --cpus-per-task=1 --mem-per-cpu=64000 --time=12:00:00 --partition=pascalnodes --job-name=GG --gres=gpu:1 --pty /bin/bash
#SBATCH --share
#SBATCH --partition=medium
#
# Name your job to make it easier for you to track
#
#SBATCH --job-name=kplex
#
# Set your error and output files
#
#SBATCH --error=%x.err
#SBATCH --output=%x.out
#SBATCH --ntasks=16
#SBATCH --cpus-per-task=1
# Tell the scheduler only need 10 minutes
#
#SBATCH --time=20:00:00
#SBATCH --mem-per-cpu=100000
#
# Set your email address and request notification when you job is complete or if it fails
#
#SBATCH --mail-type=END
#SBATCH --mail-user=akhlaque.ak@gmail.com
alias python=python3

module load GCC/13.4.0
datasets='
hamming6-2
johnson8-4-4
san200-0-9-2 
keller4
tech-WHOIS
socfb-Texas84
sc-pkustk11
socfb-UF
socfb-B-anon
sc-pwtk
soc-flixster
ia-wiki-Talk
socfb-Duke14
sc-msdoor
soc-FourSquare
sc-ldoor
soc-lastfm
soc-LiveMocha
soc-orkut
soc-BlogCatalog
soc-buzznet
soc-digg
soc-flickr
'
# remove old stuff
solutions='kplex kPlexS'
for sol in $solutions; do
    rm $sol-*.out
done
rm results.out


# for kplex in $solutions; do
for fn in $datasets; do
for k in {2..5}; do
for sol in $solutions; do
    echo "computing $fn.... " 
    srun --ntasks=1 timeout 100 ./$sol -g ~/MaximumKPlex/datasets/graphs/Chang/$fn -a exact -k $k >> $sol-$k.out &
done
done

wait

echo "================= $k =================" >> kplex-results.out
for fn in $datasets; do
echo -en "$fn\t" >> results.out
for k in {2..5}; do
for sol in $solutions; do
    outfile=$sol-$k.out
    # [ -e "$fn" ] || continue
    op=`grep $fn $outfile`
    if [ -z "${op}" ]; then 
        echo -en "-\t" >> results.out
    else
        op=($op)
        echo -en "${op[-3]}\t" >> results.out
    fi
done
done
echo >> results.out
done