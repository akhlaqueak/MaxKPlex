#!/bin/bash
# normal command for interactive session: srun --ntasks=2 --cpus-per-task=1 --mem-per-cpu=64000 --time=12:00:00 --partition=pascalnodes --job-name=GG --gres=gpu:1 --pty /bin/bash
#SBATCH --share
#SBATCH --partition=medium
#
# Name your job to make it easier for you to track
#
#SBATCH --job-name=kplex
#
# Set your error and output files
#
#SBATCH --error=%x.err
#SBATCH --output=%x.out
#SBATCH --ntasks=16
#SBATCH --cpus-per-task=1
# Tell the scheduler only need 10 minutes
#
#SBATCH --time=20:00:00
#SBATCH --mem-per-cpu=100000
#
# Set your email address and request notification when you job is complete or if it fails
#
#SBATCH --mail-type=END
#SBATCH --mail-user=akhlaque.ak@gmail.com
alias python=python3

module load GCC/13.4.0
datasets='
hamming6-2
johnson8-4-4
san200-0-9-2 
keller4
soc-flixster
ia-wiki-Talk
socfb-Duke14
sc-msdoor
soc-FourSquare
sc-ldoor
soc-lastfm
soc-LiveMocha
soc-orkut
soc-buzznet
soc-digg
'
rm kplex-*.out
rm kplex-results.out

# for kplex in $solutions; do
for k in {2..5}; do
for fn in $datasets; do
    # [ -e "$fn" ] || continue
    outfile=kplex-$k.out
    echo "computing $fn.... " 
    srun --ntasks=1 timeout 20 ./kplex-sim -g ~/MaximumKPlex/datasets/graphs/Chang/$fn -a exact -k $k >> $outfile &
    # timeout 3600 ./kplex -g ../datasets/graphs/Chang/$fn -a exact -k $k >> k$k.out
    # if [ $? -eq 124 ]; then
    # echo ">>/$fn Search_Time 99999999999" >> $outfile 
    # fi  
done
done

wait

for k in {2..5}; do
for fn in $datasets; do
    # [ -e "$fn" ] || continue
    outfile=kplex-$k.out
    op=`grep $fn $outfile`
    if [ -z "${op}" ]; then 
        echo $fn 9999999 >> kplex-results.out
    else
        echo $op >> kplex-results.out
    fi
done
done