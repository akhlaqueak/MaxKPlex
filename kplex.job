#!/bin/bash

#SBATCH --partition=medium
#
# Name your job to make it easier for you to track
#
#SBATCH --job-name=kPlexS
#
# Set your error and output files
#
#SBATCH --error=%x.err
#SBATCH --output=%x.out
#SBATCH --ntasks=16
#SBATCH --cpus-per-task=1
# Tell the scheduler only need 10 minutes
#SBATCH --time=20:00:00
#SBATCH --mem-per-cpu=10000
#
#SBATCH --mail-type=END
#SBATCH --mail-user=akhlaque.ak@gmail.com
alias python=python3

module load GCC/13.1.0

# hamming6-2
# johnson8-4-4
# san200-0-9-2 
# keller4
# tech-WHOIS
# socfb-Texas84
# sc-pkustk11
# socfb-UF
# socfb-B-anon
# sc-pwtk
# soc-flixster
datasets='
ia-wiki-Talk
socfb-Duke14
sc-msdoor
soc-FourSquare
sc-ldoor
soc-lastfm
soc-LiveMocha
soc-orkut
soc-BlogCatalog
soc-buzznet
soc-digg
soc-flickr
'
# remove old stuff
solutions='kplex'
for sol in $solutions; do
    rm $sol-*.out
done
rm results.out


# for kplex in $solutions; do
for k in {2..5}; do
for fn in $datasets; do
for sol in $solutions; do
    echo "computing $fn.... " 
    srun --nodes=1 --ntasks=1 --time=1 ./$sol -g ~/MaximumKPlex/datasets/graphs/Chang/$fn -a exact -k $k >> $sol-$k.out &
done
done
done
wait

echo "================= $k =================" >> kplex-results.out
for fn in $datasets; do
echo -en "$fn\t" >> results.out
for k in {2..5}; do
for sol in $solutions; do
    outfile=$sol-$k.out
    # [ -e "$fn" ] || continue
    op=`grep $fn $outfile`
    if [ -z "${op}" ]; then 
        echo -en "-\t" >> results.out
    else
        op=($op)
        echo -en "${op[-3]}\t" >> results.out
    fi
done
done
echo >> results.out
done